{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import derivative\n",
    "import scipy.integrate as intg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import Constant, RandomNormal\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from astroNN.nn.layers import MCDropout\n",
    "\n",
    "sys.path.append(\"/home/isidro/Documents/github/nnogada/\")\n",
    "from nnogada import Nnogada\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2903.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3521.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC5055.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2841.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC7331.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC6946.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2366.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC925.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3621.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2403.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3031.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/DDO154.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2976.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC4736.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/IC2574.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3198.NFW.fix.REV.dat', '/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC7793.NFW.fix.REV.dat']\n"
     ]
    }
   ],
   "source": [
    "# absolute path to search all text files inside a specific folder\n",
    "path = r'/home/isidro/Documents/github/model_independent_RC/data/MassModels/*.NFW.fix.REV.dat'\n",
    "files = glob.glob(path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2903.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3521.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC5055.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2841.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC7331.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC6946.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2366.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC925.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3621.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2403.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3031.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/DDO154.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC2976.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC4736.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/IC2574.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC3198.NFW.fix.REV.dat\n",
      "/home/isidro/Documents/github/model_independent_RC/data/MassModels/NGC7793.NFW.fix.REV.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_regression_dropout(num_nodes, num_hidden_layers):\n",
    "    # Defeine Keras model for regression\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(batch_input_shape=((None, 1))))\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(units=num_nodes, activation='relu'))\n",
    "        model.add(MCDropout(0.3))\n",
    "    model.add(Dense(units=2, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/17\n",
      "----------\n",
      "Len:  87\n",
      "   Radius    vgas     vdisk   vbulge   vobs  err_vobs       Vu       Vt  Rxv  \\\n",
      "0   3.327  -4.506   94.2541  54.5430  191.5    10.790  163.016  195.992  0.0   \n",
      "1   3.629  -4.679   96.8100  52.6914  200.3    10.110  166.013  199.216  0.0   \n",
      "2   3.932   5.331  100.9690  50.9203  206.7     9.159  168.624  203.101  0.0   \n",
      "3   4.234  10.290  104.1750  49.2960  211.1     8.196  170.890  206.378  0.0   \n",
      "4   4.536  13.100  104.7700  46.4151  213.5     7.037  172.868  207.813  0.0   \n",
      "\n",
      "   Vxy  \n",
      "0  0.0  \n",
      "1  0.0  \n",
      "2  0.0  \n",
      "3  0.0  \n",
      "4  0.0  \n",
      "X_train shape: (69, 1) | y_train shape: (69, 2) | x_test shape: (18, 1) | y_test shape: (18, 2)\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "history_all = []\n",
    "\n",
    "for idx, file in enumerate(files):\n",
    "    print(\"Model {}/{}\".format(idx+1, len(files)))\n",
    "    print(\"-\"*10)\n",
    "    \n",
    "    history_ind = {}\n",
    "    \n",
    "    data = np.loadtxt(files[0], skiprows=12) \n",
    "    df = pd.DataFrame(data, columns=['Radius', 'vgas', 'vdisk', 'vbulge', 'vobs', 'err_vobs', 'Vu', 'Vt','Rxv', 'Vxy'])\n",
    "    N = len(df.values)\n",
    "    print(\"Len: \", N)\n",
    "    print(df.head())\n",
    "    randomize = np.random.permutation(N)\n",
    "    data = df.values[randomize]\n",
    "\n",
    "    x = data[:,0]\n",
    "    y = data[:,1:3]\n",
    "    \n",
    "    scalerx = StandardScaler()\n",
    "    scalerx.fit(x.reshape(-1,1))\n",
    "    # apply transform\n",
    "    x = scalerx.transform(x.reshape(-1,1))\n",
    "    \n",
    "    split = 0.8\n",
    "    ntrain = int(split * len(x))\n",
    "    indx = [ntrain]\n",
    "    x_train, x_test = np.split(x, indx)\n",
    "    y_train, y_test = np.split(y, indx)\n",
    "    print(\"X_train shape: {} | y_train shape: {} | x_test shape: {} | y_test shape: {}\".format(np.shape(x_train), \n",
    "                                                                                               np.shape(y_train), np.shape(x_test), np.shape(y_test)))\n",
    "\n",
    "    population_size = 4  # max of individuals per generation\n",
    "    max_generations = 10    # number of generations\n",
    "    gene_length = 8        # lenght of the gene, depends on how many hiperparameters are tested 2*hyp\n",
    "    k = 1                  # num. of finalist individuals\n",
    "\n",
    "    # Define the hyperparameters for the search\n",
    "    hyperparams = {'deep': [3, 4], 'num_units': [100, 200], 'batch_size': [8, 16]}\n",
    "\n",
    "    # generate a Nnogada instance\n",
    "    net_fit = Nnogada(hyp_to_find=hyperparams, X_train=x_train, Y_train=y_train, X_val=x_test, Y_val=y_test, \n",
    "                      neural_library='keras', regression=True)\n",
    "    # Set the possible values of hyperparameters and not use the default values from hyperparameters.py\n",
    "    net_fit.set_hyperparameters()\n",
    "          \n",
    "    best_population = net_fit.ga_with_elitism(population_size, max_generations, gene_length, k)\n",
    "          \n",
    "    deep = int(best_population['deep'])\n",
    "    num_units = int(best_population['num_units'])\n",
    "    batch_size = int(best_population['batch_size'])\n",
    "          \n",
    "    \n",
    "    # optimizer = Adam(lr=.005)\n",
    "    optimizer = Adam(lr=0.0005)\n",
    "\n",
    "\n",
    "    # Compile Keras model\n",
    "    model = model_regression_dropout(num_nodes=num_units, num_hidden_layers=num_units)\n",
    "    print(model.summary())\n",
    "          \n",
    "    model.compile(loss='mse', optimizer=optimizer) \n",
    "  \n",
    "    model_train = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                            epochs=1000, verbose=1,\n",
    "                            validation_data=(x_test, y_test))\n",
    "    \n",
    "    model_train.history['val_loss'][-1]\n",
    "          \n",
    "        \n",
    "    history_ind['idx'] = idx\n",
    "    history_ind['deep'] = deep\n",
    "    history_ind['batch_size'] = batch_size\n",
    "    history_ind['num_units'] = num_units\n",
    "    history_ind['loss'] = model_train.history['val_loss'][-1]\n",
    "          \n",
    "    history_all.append(history_ind)\n",
    "    \n",
    "          \n",
    "    model.save('models/RC_model_{}.h5'.format(idx))\n",
    "  \n",
    "\n",
    "    # Generate test data\n",
    "    test_batch_size = 1000\n",
    "    # x_test = np.random.uniform(0, 2., test_batch_size)\n",
    "    x_test = np.linspace(3, 1150, test_batch_size)\n",
    "\n",
    "    mc_dropout_num = 100  # Run Dropout 100 times\n",
    "    predictions = np.zeros((mc_dropout_num, test_batch_size, 2))\n",
    "    uncertainty = np.zeros((mc_dropout_num, test_batch_size, 1))\n",
    "    for i in range(mc_dropout_num):\n",
    "        predictions[i] = model.predict(scalerx.transform(x_test.reshape(-1,1)))\n",
    "\n",
    "    # get mean results and its varience\n",
    "    prediction_mc_dropout = np.mean(predictions, axis=0)\n",
    "    std_mc_dropout = np.std(predictions, axis=0)\n",
    "    \n",
    "    # plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    overlapping = 0.6\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 7), dpi=100)\n",
    "    sigma = np.sqrt(std_mc_dropout[:, 0]**2 + std_mc_dropout[:, 1]**2+ prediction_mc_dropout[:,1]**2)\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(df['Radius'].values, df['Vt'].values, color='k', linewidth=3, label='NFW theory',alpha=1)\n",
    "\n",
    "    plt.errorbar(df['Radius'].values, df['vobs'].values, yerr=df['err_vobs'].values, fmt='.', \n",
    "                 color='red', elinewidth=1, ecolor='red', markersize=5, label='Observations', alpha=overlapping)\n",
    "\n",
    "    plt.errorbar(x_test, prediction_mc_dropout[:,0], yerr=sigma, markersize=2, fmt='o', \n",
    "                 ecolor='green', capthick=2, elinewidth=0.5, alpha=overlapping-0.2, c='green',\n",
    "                 label='Neural reconstruction')\n",
    "\n",
    "\n",
    "    plt.ylabel(\"$V(r)$\", fontsize=20)\n",
    "    plt.xlabel(\"r\", fontsize=20)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"neural_reconstruction_RC_{}.png\".format(idx), dpi=100)\n",
    "          \n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "\n",
    "    plt.plot(model_train.history['loss'], color='r', )\n",
    "    plt.plot(model_train.history['val_loss'], color='g')\n",
    "\n",
    "    plt.ylabel('MSE', fontsize=11)\n",
    "    plt.xlabel('Epoch', fontsize=11)\n",
    "    plt.legend(['training set', 'validation set'], loc='upper right', fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.savefig('loss_fn_neural_RC_{}'.format(idx), dpi=100)\n",
    "    print(\"-\"*10)\n",
    "    # plt.ylim(0, 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
